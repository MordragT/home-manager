From ce8a0310e85e07270ef9f006ef9e974a3c5f0000 Mon Sep 17 00:00:00 2001
From: "Yu, Guangye" <106960996+guangyey@users.noreply.github.com>
Date: Fri, 15 Sep 2023 00:16:02 +0800
Subject: [PATCH 02/17] Add xpu legacy profiler (#163)

* Add xpu legacy profiler

(cherry picked from commit c4422a87bf40fe2fc7ea6ca9a81989ba280c8b93)
---
 torch/_C/_autograd.pyi                        |   1 +
 torch/autograd/profiler.py                    |  37 +++-
 torch/autograd/profiler_legacy.py             | 115 +++++++---
 torch/autograd/profiler_util.py               | 202 +++++++++++++++---
 torch/csrc/autograd/init.cpp                  |  10 +
 torch/csrc/autograd/profiler_kineto.h         |   4 +-
 torch/csrc/autograd/profiler_legacy.cpp       |  94 ++++++--
 torch/csrc/autograd/profiler_legacy.h         |  55 ++++-
 torch/csrc/profiler/collection.h              |   4 +-
 torch/csrc/profiler/orchestration/observer.h  |   1 +
 torch/csrc/profiler/python/init.cpp           |   1 +
 torch/csrc/profiler/stubs/base.cpp            |   9 +-
 torch/csrc/profiler/stubs/base.h              |  19 +-
 torch/csrc/profiler/stubs/cuda.cpp            |  47 ++--
 torch/csrc/profiler/stubs/itt.cpp             |  10 +-
 .../_internal/distributed/rpc/rpc_test.py     |   4 +-
 16 files changed, 493 insertions(+), 120 deletions(-)

diff --git a/torch/_C/_autograd.pyi b/torch/_C/_autograd.pyi
index 0a92d31b323..44c287a8268 100644
--- a/torch/_C/_autograd.pyi
+++ b/torch/_C/_autograd.pyi
@@ -15,6 +15,7 @@ from ._profiler import (
 class DeviceType(Enum):
     CPU = ...
     CUDA = ...
+    XPU = ...
     MKLDNN = ...
     OPENGL = ...
     OPENCL = ...
diff --git a/torch/autograd/profiler.py b/torch/autograd/profiler.py
index 650546fac4c..a784b09176f 100644
--- a/torch/autograd/profiler.py
+++ b/torch/autograd/profiler.py
@@ -128,6 +128,8 @@ class profile:
         use_cuda (bool, optional): Enables timing of CUDA events as well using the cudaEvent API.
             Adds approximately 4us of overhead to each tensor operation.
 
+        use_xpu (bool, optional): Enables timing of XPU events as well using the xpuEvent API.
+
         record_shapes (bool, optional): If shapes recording is set, information
             about input dimensions will be collected. This allows one to see which
             dimensions have been used under the hood and further group by them
@@ -206,6 +208,7 @@ class profile:
         *,
         use_cuda=False,
         use_device=None,
+        use_xpu=False,
         record_shapes=False,
         with_flops=False,
         profile_memory=False,
@@ -223,6 +226,7 @@ class profile:
         self.use_device: Optional[str] = (
             use_device if use_device != "privateuseone" else None
         )
+        self.use_xpu = use_xpu
         self.function_events: Optional[EventList] = None
         self.entered = False
         self.record_shapes = record_shapes
@@ -247,6 +251,10 @@ class profile:
             self.use_device = None
             self.use_cuda = True
 
+        if self.use_device == "xpu":
+            self.use_device = None
+            self.use_xpu= True
+
         if self.use_device and self.use_device != _get_privateuse1_backend_name():
             warn(f"{self.use_device} doesn't support profile.")
             self.use_device = None
@@ -255,6 +263,10 @@ class profile:
             warn("CUDA is not available, disabling CUDA profiling")
             self.use_cuda = False
 
+        if self.use_xpu and not (hasattr(torch, "xpu") and torch.xpu.is_available()):    # type: ignore[attr-defined]
+            warn("XPU is not available, disabling XPU profiling")
+            self.use_xpu = False
+
         self.kineto_activities = set()
         if self.use_cpu:
             self.kineto_activities.add(ProfilerActivity.CPU)
@@ -268,6 +280,9 @@ class profile:
                 self.profiler_kind = ProfilerState.KINETO_GPU_FALLBACK
             else:
                 self.kineto_activities.add(ProfilerActivity.CUDA)
+        elif self.use_xpu:
+            # legacy XPU mode
+            self.profiler_kind = ProfilerState.XPU
 
         if self.use_device:
             if (
@@ -327,6 +342,7 @@ class profile:
             parsed_results,
             use_cuda=self.use_cuda,
             use_device=self.use_device,
+            use_xpu=self.use_xpu,
             profile_memory=self.profile_memory,
             with_flops=self.with_flops,
         )
@@ -502,13 +518,20 @@ class profile:
                 if self.use_device:
                     privateuse1_time = kineto_event.privateuse1_elapsed_us()
                     if privateuse1_time > 0:
-                        fe.append_kernel(fe.name, fe.device_index, privateuse1_time)
+                        fe.append_kernel(
+                            fe.name,
+                            torch.device("{}:{}".format(self.use_device, fe.device_index)),
+                            fe.device_index,
+                            privateuse1_time)
                         fe.is_legacy = True
                 else:
                     # Check if we have CUDA time as a fallback
                     cuda_time = kineto_event.cuda_elapsed_us()
                     if cuda_time > 0:
-                        fe.append_kernel(fe.name, fe.device_index, cuda_time)
+                        fe.append_kernel(
+                            fe.name,
+                            torch.device("cuda:{}".format(fe.device_index)),
+                            cuda_time)
                         fe.is_legacy = True
             function_events.append(fe)
             corr_id = kineto_event.linked_correlation_id()
@@ -528,9 +551,8 @@ class profile:
                     if f_evt.device_type == DeviceType.CUDA:
                         fe.append_kernel(
                             f_evt.name,
-                            f_evt.device_index,
-                            f_evt.time_range.end - f_evt.time_range.start,
-                        )
+                            torch.device("cuda:{}".format(fe.device_index)),
+                            f_evt.time_range.end - f_evt.time_range.start)
                     elif f_evt.device_type == DeviceType.CPU:
                         # make sure that 'thread' of a CPU Kineto (e.g. CUDA Runtime) event is associated
                         # with the 'thread' of the corresponding linked PyTorch event to properly track
@@ -968,8 +990,9 @@ def parse_nvprof_trace(path):
         assert row["cbid"] == 211
         evt = functions_map[row["marker_id"]]
         evt.append_kernel(
-            row["kernel_name"], 0, row["kernel_end"] - row["kernel_start"]
-        )
+            row["kernel_name"],
+            torch.device("cuda:0"),
+            row["kernel_end"] - row["kernel_start"])
 
     functions.sort(key=lambda evt: evt.time_range.start)
     return functions
diff --git a/torch/autograd/profiler_legacy.py b/torch/autograd/profiler_legacy.py
index 5de0965bc41..6ac237cf2b5 100644
--- a/torch/autograd/profiler_legacy.py
+++ b/torch/autograd/profiler_legacy.py
@@ -18,6 +18,7 @@ from torch.autograd.profiler_util import (
     EventList,
     FunctionEvent,
     MEMORY_EVENT_NAME,
+    Interval,
 )
 
 __all__ = ["profile"]
@@ -31,8 +32,10 @@ class profile:
         enabled=True,
         *,
         use_cuda=False,
+        use_xpu=False,
         record_shapes=False,
         with_flops=False,
+        with_calling_stack=False,
         profile_memory=False,
         with_stack=False,
         with_modules=False,
@@ -41,10 +44,12 @@ class profile:
         if not self.enabled:
             return
         self.use_cuda = use_cuda
+        self.use_xpu = use_xpu
         self.function_events = None
         self.entered = False
         self.record_shapes = record_shapes
         self.with_flops = with_flops
+        self.with_calling_stack = with_calling_stack
         self.record_shapes |= self.with_flops
         self.profile_memory = profile_memory
         self.with_stack = with_stack
@@ -54,8 +59,14 @@ class profile:
             warn("CUDA is not available, disabling CUDA profiling")
             self.use_cuda = False
 
+        if self.use_xpu and not (hasattr(torch, "xpu") and torch.xpu.is_available()):    # type: ignore[attr-defined]
+            warn("XPU is not available, disabling XPU profiling")
+            self.use_xpu = False
+
         if self.use_cuda:
             self.profiler_kind = ProfilerState.CUDA
+        elif self.use_xpu:
+            self.profiler_kind = ProfilerState.XPU
         else:
             self.profiler_kind = ProfilerState.CPU
 
@@ -88,14 +99,18 @@ class profile:
             return
         if self.use_cuda:
             torch.cuda.synchronize()
+        if self.use_xpu:
+            torch.xpu.synchronize()    # type: ignore[attr-defined]
 
         records = _disable_profiler_legacy()
         parsed_results = _parse_legacy_records(records)
         self.function_events = EventList(
             parsed_results,
             use_cuda=self.use_cuda,
+            use_xpu=self.use_xpu,
             profile_memory=self.profile_memory,
             with_flops=self.with_flops,
+            with_calling_stack=self.with_calling_stack,
         )
         self.function_events._build_tree()
         return False
@@ -121,6 +136,7 @@ class profile:
         max_src_column_width=75,
         max_name_column_width=55,
         max_shapes_column_width=80,
+        max_depth=10,
         header=None,
         top_level_events_only=False,
     ):
@@ -132,6 +148,7 @@ class profile:
             max_src_column_width=max_src_column_width,
             max_name_column_width=max_name_column_width,
             max_shapes_column_width=max_shapes_column_width,
+            max_depth=max_depth,
             header=header,
             top_level_events_only=top_level_events_only,
         )
@@ -200,8 +217,12 @@ def _parse_legacy_records(thread_records):
         # accumulated memory allocations per handle
         cpu_memory_allocs = {}
         cuda_memory_allocs = {}
+        xpu_memory_allocs = {}
         # ranges per handle
         range_starts = {}
+        function_stack = []
+        calling_stack = []
+        calling_id = 0
 
         filtered_handles = set()
         prev_record = None
@@ -224,55 +245,69 @@ def _parse_legacy_records(thread_records):
                         filtered_handles.add(record_key)
                         continue
 
-                range_starts[record_key] = record
+                calling_stack.append(calling_id + 1)
+                calling_id = 0
+                # create the function event for appending kernel
+                fe = FunctionEvent(
+                    id=record.handle(),
+                    name=_rewrite_name(name=record.name(), with_wildcard=True),
+                    thread=record.thread_id(),
+                    start_us=0,
+                    end_us=0,
+                    stack=[],
+                    node_id=record.node_id(),
+                    input_shapes=record.shapes(),
+                    cstack=tuple(calling_stack),
+                    device_type=DeviceType.CPU,
+                    is_legacy=True,
+                )
+                function_stack.append(fe)
+                range_starts[record_key] = (record, fe)
                 cpu_memory_allocs[record_key] = 0
                 cuda_memory_allocs[record_key] = 0
+                xpu_memory_allocs[record_key] = 0
             elif record.kind() == "pop":
                 assert (
                     record_key in range_starts
                 ), f"""Expected record with key {record_key} to exist in range_starts.
                     This means that the pop event did not have a corresponding push."""
 
-                start = range_starts[record_key]
+                start, fe = range_starts[record_key]
+
+                calling_id = calling_stack.pop()
 
                 cpu_memory_usage = cpu_memory_allocs[record_key]
                 cuda_memory_usage = cuda_memory_allocs[record_key]
+                xpu_memory_usage = xpu_memory_allocs[record_key]
                 is_async = start.is_async() or (start.thread_id() != record.thread_id())
                 is_remote_event = record.is_remote()
                 start_flops = start.flops()
 
-                fe = FunctionEvent(
-                    id=record.handle(),
-                    node_id=record.node_id(),
-                    name=_rewrite_name(name=start.name(), with_wildcard=True),
-                    trace_name=_rewrite_name(name=start.name(), with_wildcard=False),
-                    thread=start.thread_id(),
-                    start_us=start_record.cpu_elapsed_us(start),
-                    end_us=start_record.cpu_elapsed_us(record),
-                    fwd_thread=start.fwd_thread_id(),
-                    input_shapes=start.shapes(),
-                    stack=[
-                        entry for entry in start.stack() if _filter_stack_entry(entry)
-                    ],
-                    scope=start.scope(),
-                    cpu_memory_usage=cpu_memory_usage,
-                    cuda_memory_usage=cuda_memory_usage,
-                    is_async=is_async,
-                    is_remote=is_remote_event,
-                    sequence_nr=start.sequence_nr(),
-                    device_type=DeviceType.CPU,
-                    is_legacy=True,
-                    flops=start_flops,
-                )
+                fe.time_range = Interval(start_record.cpu_elapsed_us(start), start_record.cpu_elapsed_us(record))
+                fe.cpu_memory_usage = cpu_memory_usage
+                fe.cuda_memory_usage = cuda_memory_usage
+                fe.xpu_memory_usage = xpu_memory_usage
+                fe.is_async = is_async
+                fe.is_remote = is_remote_event
+                fe.fwd_thread = start.fwd_thread_id()
+                fe.stack = [entry for entry in start.stack() if _filter_stack_entry(entry)]
+                fe.scope = start.scope()
+                fe.sequence_nr = start.sequence_nr()
+                fe.trace_name = _rewrite_name(name=start.name(), with_wildcard=False)
+                fe.fwd_thread = start.fwd_thread_id()
+                fe.flops = start_flops
+
                 # note: async events have only cpu total time
                 if not is_async and start.has_cuda():
                     duration = start.cuda_elapsed_us(record)
                     if duration > 0:
                         fe.append_kernel(start.name(), start.device(), duration)
                 functions.append(fe)
+                function_stack.remove(fe)
                 del range_starts[record_key]
                 del cpu_memory_allocs[record_key]
                 del cuda_memory_allocs[record_key]
+                del xpu_memory_allocs[record_key]
             elif record.kind() == "memory_alloc":
                 num_open_handles_cpu = len(cpu_memory_allocs)
                 num_open_handles_cuda = len(cuda_memory_allocs)
@@ -281,6 +316,8 @@ def _parse_legacy_records(thread_records):
                     cpu_memory_allocs[handle] += record.cpu_memory_usage()
                 for handle in cuda_memory_allocs.keys():
                     cuda_memory_allocs[handle] += record.cuda_memory_usage()
+                for handle in xpu_memory_allocs.keys():
+                    xpu_memory_allocs[handle] += record.xpu_memory_usage()
                 if num_open_handles_cpu == 0:
                     # output event as a top-level memory event
                     fe = FunctionEvent(
@@ -293,9 +330,37 @@ def _parse_legacy_records(thread_records):
                         stack=[],
                         cpu_memory_usage=record.cpu_memory_usage(),
                         cuda_memory_usage=record.cuda_memory_usage(),
+                        xpu_memory_usage=record.xpu_memory_usage(),
                         is_legacy=True,
                     )
                     functions.append(fe)
+            elif record.kind() == "mark":
+                if "__xpu_start_event" in record.name():
+                    continue
+                if record.has_xpu():
+                    if len(function_stack) > 0:
+                        fe = function_stack[-1]
+                        fe.append_kernel(fe.name + "(" + record.name() + ")",
+                                         record.device(),
+                                         record.xpu_elapsed_us())
+                    else:
+                        # An xpu event is recorded but no parent function was recorded.
+                        fe = FunctionEvent(
+                            id=record.handle(),
+                            node_id=record.node_id(),
+                            name=_rewrite_name(name=record.name(), with_wildcard=True),
+                            thread=record.thread_id(),
+                            start_us=0,
+                            end_us=0,
+                            stack=[],
+                            cstack=tuple(calling_stack),
+                            input_shapes=record.shapes(),
+                            is_legacy=True)
+                        fe.stack = []
+                        fe.append_kernel(fe.name + "(" + record.name() + ")",
+                                         record.device(),
+                                         record.xpu_elapsed_us())
+                        functions.append(fe)
             prev_record = record
 
     # Sort functions by start time then by end time ascending.
diff --git a/torch/autograd/profiler_util.py b/torch/autograd/profiler_util.py
index de330f10a4f..3a88f72ab4e 100644
--- a/torch/autograd/profiler_util.py
+++ b/torch/autograd/profiler_util.py
@@ -28,14 +28,18 @@ class EventList(list):
     def __init__(self, *args, **kwargs):
         use_cuda = kwargs.pop("use_cuda", True)
         use_device = kwargs.pop("use_device", None)
+        use_xpu = kwargs.pop("use_xpu", False)
         profile_memory = kwargs.pop("profile_memory", False)
         with_flops = kwargs.pop("with_flops", False)
+        with_calling_stack = kwargs.pop("with_calling_stack", False)
         super().__init__(*args, **kwargs)
         self._use_cuda = use_cuda
         self._use_device = use_device
+        self._use_xpu = use_xpu
         self._profile_memory = profile_memory
         self._tree_built = False
         self._with_flops = with_flops
+        self._with_calling_stack = with_calling_stack
 
     def _build_tree(self):
         self._populate_cpu_children()
@@ -173,6 +177,7 @@ class EventList(list):
         max_src_column_width=75,
         max_name_column_width=55,
         max_shapes_column_width=80,
+        max_depth=10,
         header=None,
         top_level_events_only=False,
     ):
@@ -200,9 +205,11 @@ class EventList(list):
             max_src_column_width=max_src_column_width,
             max_name_column_width=max_name_column_width,
             max_shapes_column_width=max_shapes_column_width,
+            max_depth=10,
             header=header,
             profile_memory=self._profile_memory,
             with_flops=self._with_flops,
+            with_calling_stack=self._with_calling_stack,
             top_level_events_only=top_level_events_only,
         )
 
@@ -216,7 +223,12 @@ class EventList(list):
         """
         import os
 
-        device_name = "cuda" if not self._use_device else self._use_device
+        if self._use_cuda:
+             device_name = "cuda"
+        elif self._use_device:
+             device_name = self._use_device
+        elif self._use_xpu:
+             device_name = "xpu"
         with open(path, "w") as f:
             chrome_events = []
             next_id = 0
@@ -327,8 +339,10 @@ class EventList(list):
             stats.values(),
             use_cuda=self._use_cuda,
             use_device=self._use_device,
+            use_xpu=self._use_xpu,
             profile_memory=self._profile_memory,
             with_flops=self._with_flops,
+            with_calling_stack=self._with_calling_stack,
         )
         for evt in avg_list:
             evt.stack = evt.stack[:group_by_stack_n]
@@ -397,12 +411,15 @@ class FormattedTimesMixin:
     cpu_time_str = _attr_formatter("cpu_time")
     cuda_time_str = _attr_formatter("cuda_time")
     privateuse1_time_str = _attr_formatter("privateuse1_time")
+    xpu_time_str = _attr_formatter("xpu_time")
     cpu_time_total_str = _attr_formatter("cpu_time_total")
     cuda_time_total_str = _attr_formatter("cuda_time_total")
     privateuse1_time_total_str = _attr_formatter("privateuse1_time_total")
+    xpu_time_total_str = _attr_formatter("xpu_time_total")
     self_cpu_time_total_str = _attr_formatter("self_cpu_time_total")
     self_cuda_time_total_str = _attr_formatter("self_cuda_time_total")
     self_privateuse1_time_total_str = _attr_formatter("self_privateuse1_time_total")
+    self_xpu_time_total_str = _attr_formatter("self_xpu_time_total")
 
     @property
     def cpu_time(self):
@@ -416,6 +433,10 @@ class FormattedTimesMixin:
     def privateuse1_time(self):
         return 0.0 if self.count == 0 else 1.0 * self.privateuse1_time_total / self.count  # type: ignore[attr-defined]
 
+    @property
+    def xpu_time(self):
+        return 0.0 if self.count == 0 else 1.0 * self.xpu_time_total / self.count  # type: ignore[attr-defined]
+
 
 class Interval:
     def __init__(self, start, end):
@@ -442,11 +463,13 @@ class FunctionEvent(FormattedTimesMixin):
         fwd_thread=None,
         input_shapes=None,
         stack=None,
+        cstack=None,
         scope=0,
         use_device=None,
         cpu_memory_usage=0,
         cuda_memory_usage=0,
         privateuse1_memory_usage=0,
+        xpu_memory_usage=0,
         is_async=False,
         is_remote=False,
         sequence_nr=-1,
@@ -472,11 +495,13 @@ class FunctionEvent(FormattedTimesMixin):
         self.input_shapes: Tuple[int, ...] = input_shapes
         self.concrete_inputs: List[Any] = concrete_inputs
         self.stack: List = stack
+        self.cstack: Tuple[int, ...] = cstack
         self.scope: int = scope
         self.use_device: Optional[str] = use_device
         self.cpu_memory_usage: int = cpu_memory_usage
         self.cuda_memory_usage: int = cuda_memory_usage
         self.privateuse1_memory_usage: int = privateuse1_memory_usage
+        self.xpu_memory_usage: int = xpu_memory_usage
         self.is_async: bool = is_async
         self.is_remote: bool = is_remote
         self.sequence_nr: int = sequence_nr
@@ -485,7 +510,7 @@ class FunctionEvent(FormattedTimesMixin):
         self.is_legacy: bool = is_legacy
         self.flops: Optional[int] = flops
 
-    def append_kernel(self, name, device, duration):
+    def append_kernel(self, name, device: torch.device, duration):
         assert self.device_type == DeviceType.CPU
         self.kernels.append(Kernel(name, device, duration))
 
@@ -538,6 +563,12 @@ class FunctionEvent(FormattedTimesMixin):
             [child.privateuse1_memory_usage for child in self.cpu_children]
         )
 
+    @property
+    def self_xpu_memory_usage(self):
+        if self.is_async:
+            return 0
+        return self.xpu_memory_usage - sum([child.xpu_memory_usage for child in self.cpu_children])
+
     @property
     def self_cpu_time_total(self):
         if self.is_async or self.device_type != DeviceType.CPU:
@@ -553,15 +584,15 @@ class FunctionEvent(FormattedTimesMixin):
         if self.device_type == DeviceType.CPU:
             if not self.is_legacy:
                 # account for the kernels in the children ops
-                return sum(kinfo.duration for kinfo in self.kernels) + sum(
-                    ch.cuda_time_total for ch in self.cpu_children
-                )
+                return (sum(kinfo.duration for kinfo in self.kernels if kinfo.device.type == DeviceType.CUDA) +
+                        sum(ch.cuda_time_total for ch in self.cpu_children))
             else:
                 # each legacy cpu events has a single (fake) kernel
-                return sum(kinfo.duration for kinfo in self.kernels)
-        else:
-            assert self.device_type == DeviceType.CUDA
+                return sum(kinfo.duration for kinfo in self.kernels if kinfo.device.type == DeviceType.CUDA)
+        elif self.device_type == DeviceType.CUDA:
             return self.time_range.elapsed_us()
+        else:
+            return 0
 
     @property
     def self_cuda_time_total(self):
@@ -571,9 +602,10 @@ class FunctionEvent(FormattedTimesMixin):
             return self.cuda_time_total - sum(
                 [child.cuda_time_total for child in self.cpu_children]
             )
-        else:
-            assert self.device_type == DeviceType.CUDA
+        elif self.device_type == DeviceType.CUDA:
             return self.cuda_time_total
+        else:
+            return 0
 
     @property
     def cpu_time_total(self):
@@ -611,23 +643,46 @@ class FunctionEvent(FormattedTimesMixin):
             assert self.device_type == DeviceType.PrivateUse1
             return self.time_range.elapsed_us()
 
+    @property
+    def xpu_time_total(self):
+        if self.is_async:
+            return 0
+        if self.device_type == DeviceType.CPU:
+            # account for the kernels in the children ops
+            return (sum(kinfo.duration for kinfo in self.kernels if kinfo.device.type == "xpu") +
+                    sum(ch.xpu_time_total for ch in self.cpu_children))
+        elif self.device_type == DeviceType.XPU:
+            return self.time_range.elapsed_us()
+        else:
+            return 0
+
+    @property
+    def self_xpu_time_total(self):
+        if self.is_async:
+            return 0
+        else:
+            return sum(kinfo.duration for kinfo in self.kernels if kinfo.device.type == "xpu")
+
     @property
     def key(self):
         return self.name
 
     def __repr__(self):
-        device_name = "cuda" if not self.use_device else self.use_device
-        device_time = (
-            self.cuda_time_str if not self.use_device else self.privateuse1_time_str
-        )
-        device_memory_usage = (
-            self.cuda_memory_usage
-            if not self.use_device
-            else self.privateuse1_memory_usage
-        )
+        if self.device_type == "cuda":
+            device_name = "cuda"
+            device_time = self.cuda_time_str
+            device_memory_usage = self.cuda_memory_usage
+        elif self.use_device:
+            device_name = self.use_device
+            device_time = self.privateuse1_time_str
+            device_memory_usage = self.privateuse1_memory_usage
+        elif self.device_type == "xpu":
+            device_name = "xpu"
+            device_time = self.xpu_time_str
+            device_memory_usage = self.xpu_memory_usage
         return (
             "<FunctionEvent id={} name={} device_type={} node_id={} cpu_time={} start_us={} end_us={} "
-            "cpu_children={} {}_time={} name={} thread={} input_shapes={} "
+            "cpu_children={} {}_time={} name={} thread={} input_shapes={} cstack={} "
             "cpu_memory_usage={} {}_memory_usage={} is_async={} is_remote={} seq_nr={} is_legacy={}>".format(
                 self.id,
                 self.name,
@@ -642,6 +697,7 @@ class FunctionEvent(FormattedTimesMixin):
                 self.name,
                 self.thread,
                 str(self.input_shapes),
+                str(self.cstack),
                 self.cpu_memory_usage,
                 device_name,
                 device_memory_usage,
@@ -666,18 +722,23 @@ class FunctionEventAvg(FormattedTimesMixin):
         self.cpu_time_total: int = 0
         self.cuda_time_total: int = 0
         self.privateuse1_time_total: int = 0
+        self.xpu_time_total: int = 0
         self.self_cpu_time_total: int = 0
         self.self_cuda_time_total: int = 0
         self.self_privateuse1_time_total: int = 0
+        self.self_xpu_time_total: int = 0
         self.input_shapes: Optional[List[List[int]]] = None
         self.stack: Optional[List] = None
+        self.cstack: Optional[List] = None
         self.scope: Optional[int] = None
         self.cpu_memory_usage: int = 0
         self.cuda_memory_usage: int = 0
         self.privateuse1_memory_usage: int = 0
+        self.xpu_memory_usage: int = 0
         self.self_cpu_memory_usage: int = 0
         self.self_cuda_memory_usage: int = 0
         self.self_privateuse1_memory_usage: int = 0
+        self.self_xpu_memory_usage: int = 0
         self.cpu_children: Optional[List[FunctionEvent]] = None
         self.cpu_parent: Optional[FunctionEvent] = None
         self.device_type: DeviceType = DeviceType.CPU
@@ -697,6 +758,7 @@ class FunctionEventAvg(FormattedTimesMixin):
 
             self.input_shapes = other.input_shapes
             self.stack = other.stack
+            self.cstack = other.cstack
             self.scope = other.scope
             self.device_type = other.device_type
             self.is_legacy = other.is_legacy
@@ -707,15 +769,19 @@ class FunctionEventAvg(FormattedTimesMixin):
         self.cpu_time_total += other.cpu_time_total
         self.cuda_time_total += other.cuda_time_total
         self.privateuse1_time_total += other.privateuse1_time_total
+        self.xpu_time_total += other.xpu_time_total
         self.self_cpu_time_total += other.self_cpu_time_total
         self.self_cuda_time_total += other.self_cuda_time_total
         self.self_privateuse1_time_total += other.self_privateuse1_time_total
+        self.self_xpu_time_total += other.self_xpu_time_total
         self.cpu_memory_usage += other.cpu_memory_usage
         self.cuda_memory_usage += other.cuda_memory_usage
         self.privateuse1_memory_usage += other.privateuse1_memory_usage
+        self.xpu_memory_usage += other.xpu_memory_usage
         self.self_cpu_memory_usage += other.self_cpu_memory_usage
         self.self_cuda_memory_usage += other.self_cuda_memory_usage
         self.self_privateuse1_memory_usage += other.self_privateuse1_memory_usage
+        self.self_xpu_memory_usage += other.self_xpu_memory_usage
         self.count += other.count
         if self.flops is None:
             self.flops = other.flops
@@ -727,23 +793,24 @@ class FunctionEventAvg(FormattedTimesMixin):
         return self.add(other)
 
     def __repr__(self):
-        device_name = "cuda" if not self.use_device else self.use_device
-        self_device_time = (
-            self.self_cuda_time_total_str
-            if not self.use_device
-            else self.self_privateuse1_time_total_str
-        )
-        device_time = (
-            self.cuda_time_str if not self.use_device else self.privateuse1_time_str
-        )
-        device_memory = (
-            self.cuda_memory_usage
-            if not self.use_device
-            else self.privateuse1_memory_usage
-        )
+        if self.device_type == "cuda":
+            device_name = "cuda"
+            self_device_time = self.self_cuda_time_total_str
+            device_time = self.cuda_time_str
+            device_memory = self.cuda_memory_usage
+        elif self.use_device:
+            device_name = self.use_device
+            self_device_time = self.self_privateuse1_time_total_str
+            device_time = self.privateuse1_time_str
+            device_memory = self.privateuse1_memory_usage
+        elif self.device_type == "xpu":
+            device_name = "xpu"
+            self_device_time = self.self_xpu_time_total_str
+            device_time = self.xpu_time_str
+            device_memory = self.xpu_memory_usage
         return (
             "<FunctionEventAvg key={} self_cpu_time={} cpu_time={} "
-            " self_{}_time={} {}_time={} input_shapes={} "
+            " self_{}_time={} {}_time={} input_shapes={} cstack={} "
             "cpu_memory_usage={} {}_memory_usage={}>".format(
                 self.key,
                 self.self_cpu_time_total_str,
@@ -753,6 +820,7 @@ class FunctionEventAvg(FormattedTimesMixin):
                 device_name,
                 device_time,
                 str(self.input_shapes),
+                str(self.cstack),
                 self.cpu_memory_usage,
                 device_name,
                 device_memory,
@@ -839,7 +907,9 @@ def _build_table(
     max_src_column_width=75,
     max_name_column_width=55,
     max_shapes_column_width=80,
+    max_depth=10,
     with_flops=False,
+    with_calling_stack=False,
     profile_memory=False,
     top_level_events_only=False,
 ):
@@ -855,6 +925,8 @@ def _build_table(
     has_privateuse1_mem = any(
         event.self_privateuse1_memory_usage > 0 for event in events
     )
+    has_xpu_time = any([event.self_xpu_time_total > 0 for event in events])
+    has_xpu_mem = any([event.self_xpu_memory_usage > 0 for event in events])
     use_device = events[0].use_device
     if not use_device and (has_privateuse1_mem or has_privateuse1_time):
         raise RuntimeError(
@@ -871,8 +943,10 @@ def _build_table(
             sorted(events, key=lambda evt: getattr(evt, sort_by), reverse=True),
             use_cuda=has_cuda_time,
             use_device=use_device,
+            use_xpu=has_xpu_time,
             profile_memory=profile_memory,
             with_flops=with_flops,
+            with_calling_stack=with_calling_stack,
         )
 
     name_column_width = max([len(evt.key) for evt in events]) + 4
@@ -886,6 +960,10 @@ def _build_table(
     DEFAULT_COLUMN_WIDTH = 12
     flops_column_width = DEFAULT_COLUMN_WIDTH
 
+    if with_calling_stack:
+        cstack_column_width = max([len(str(evt.cstack[:max_depth])[1:-1]) for evt in events]) + 8
+        cstack_column_width = max(cstack_column_width, 20)
+
     src_column_width = None
     stacks = []
     for evt in events:
@@ -926,6 +1004,15 @@ def _build_table(
                 f"{privateuse1} time avg",
             ]
         )
+    if has_xpu_time:
+        headers.extend(
+            [
+                "Self XPU",
+                "Self XPU %",
+                "XPU total",
+                "XPU time avg",
+            ]
+        )
     if profile_memory:
         headers.extend(
             [
@@ -948,6 +1035,13 @@ def _build_table(
                     f"Self {privateuse1} Mem",
                 ]
             )
+        if has_xpu_mem:
+            headers.extend(
+                [
+                    "XPU Mem",
+                    "Self XPU Mem",
+                ]
+            )
     headers.append("# of Calls")
     # Only append Node ID if any event has a valid (>= 0) Node ID
     append_node_id = any(evt.node_id != -1 for evt in events)
@@ -1007,6 +1101,10 @@ def _build_table(
         else:
             with_flops = False  # can't find any valid flops
 
+    if with_calling_stack:
+        headers.append("Calling Stack Tree".ljust(cstack_column_width))
+        add_column(cstack_column_width)
+
     row_format = row_format_lst[0]
     header_sep = header_sep_lst[0]
     line_length = line_length_lst[0]
@@ -1022,12 +1120,14 @@ def _build_table(
     sum_self_cpu_time_total = sum([event.self_cpu_time_total for event in events])
     sum_self_cuda_time_total = 0
     sum_self_privateuse1_time_total = 0
+    sum_self_xpu_time_total = 0
     for evt in events:
         if evt.device_type == DeviceType.CPU:
             # in legacy profiler, kernel info is stored in cpu events
             if evt.is_legacy:
                 if not use_device:
                     sum_self_cuda_time_total += evt.self_cuda_time_total
+                    sum_self_xpu_time_total += evt.self_xpu_time_total
                 else:
                     sum_self_privateuse1_time_total += evt.self_privateuse1_time_total
         elif evt.device_type == DeviceType.CUDA:
@@ -1035,6 +1135,9 @@ def _build_table(
             sum_self_cuda_time_total += evt.self_cuda_time_total
         elif evt.device_type == DeviceType.PrivateUse1:
             sum_self_privateuse1_time_total += evt.self_privateuse1_time_total
+        elif evt.device_type == DeviceType.XPU:
+            # The XPU doesn't support kineto yet
+            pass
 
     # Actual printing
     if header is not None:
@@ -1103,6 +1206,18 @@ def _build_table(
                     evt.privateuse1_time_str,  # PrivateUse1 time avg
                 ]
             )
+        if has_xpu_time:
+            row_values.extend(
+                [
+                    evt.self_xpu_time_total_str,
+                    # SYCL time total %
+                    _format_time_share(
+                        evt.self_xpu_time_total, sum_self_xpu_time_total
+                    ),
+                    evt.xpu_time_total_str,
+                    evt.xpu_time_str,   # SYCL time avg
+                ]
+            )
         if profile_memory:
             row_values.extend(
                 [
@@ -1130,6 +1245,15 @@ def _build_table(
                         _format_memory(evt.self_privateuse1_memory_usage),
                     ]
                 )
+            if has_xpu_mem:
+                row_values.extend(
+                    [
+                        # SYCL Mem Total
+                        _format_memory(evt.xpu_memory_usage),
+                        # Self SYCL Mem Total
+                        _format_memory(evt.self_xpu_memory_usage),
+                    ]
+                )
         row_values.append(
             evt.count,  # Number of calls
         )
@@ -1148,6 +1272,12 @@ def _build_table(
             if len(evt.stack) > 0:
                 src_field = trim_path(evt.stack[0], src_column_width)
             row_values.append(src_field)
+        if with_calling_stack:
+            if len(evt.cstack) > max_depth:
+                cstack_str = str(evt.cstack[:max_depth])[1:-1] + ",..."
+            else:
+                cstack_str = str(evt.cstack)[1:-1]
+            row_values.append(cstack_str.ljust(cstack_column_width))
         append(row_format.format(*row_values))
 
         if has_stack:
@@ -1169,4 +1299,6 @@ def _build_table(
         append(
             f"Self {use_device.upper()} time total: {_format_time(sum_self_privateuse1_time_total)}"
         )
+    if has_xpu_time:
+        append(f"Self XPU time total: {_format_time(sum_self_xpu_time_total)}")
     return "".join(result)
diff --git a/torch/csrc/autograd/init.cpp b/torch/csrc/autograd/init.cpp
index 746695eb714..b078692e03b 100644
--- a/torch/csrc/autograd/init.cpp
+++ b/torch/csrc/autograd/init.cpp
@@ -130,10 +130,20 @@ PyObject* THPAutograd_initExtension(PyObject* _unused, PyObject* unused) {
       .def("device", &LegacyEvent::device)
       .def("cpu_elapsed_us", &LegacyEvent::cpuElapsedUs)
       .def("cuda_elapsed_us", &LegacyEvent::cudaElapsedUs)
+      .def(
+          "xpu_elapsed_us",
+          static_cast<double (LegacyEvent::*)(void) const>(
+              &LegacyEvent::xpuElapsedUs))
+      .def(
+          "xpu_elapsed_us",
+          static_cast<double (LegacyEvent::*)(const LegacyEvent& e) const>(
+              &LegacyEvent::xpuElapsedUs))
       .def("has_cuda", &LegacyEvent::hasCuda)
+      .def("has_xpu", &LegacyEvent::hasXpu)
       .def("shapes", &LegacyEvent::shapes)
       .def("cpu_memory_usage", &LegacyEvent::cpuMemoryUsage)
       .def("cuda_memory_usage", &LegacyEvent::cudaMemoryUsage)
+      .def("xpu_memory_usage", &LegacyEvent::xpuMemoryUsage)
       .def("handle", &LegacyEvent::handle)
       .def("node_id", &LegacyEvent::nodeId)
       .def("is_remote", &LegacyEvent::isRemote)
diff --git a/torch/csrc/autograd/profiler_kineto.h b/torch/csrc/autograd/profiler_kineto.h
index 6d059498496..2a6b2a6b710 100644
--- a/torch/csrc/autograd/profiler_kineto.h
+++ b/torch/csrc/autograd/profiler_kineto.h
@@ -61,8 +61,8 @@ struct TORCH_API KinetoEvent {
   void getPerfEventCounters(torch::profiler::perf_counters_t&) const;
 
  private:
-  torch::profiler::impl::ProfilerVoidEventStub fallbackStart() const;
-  torch::profiler::impl::ProfilerVoidEventStub fallbackEnd() const;
+  torch::profiler::impl::ProfilerEventStub fallbackStart() const;
+  torch::profiler::impl::ProfilerEventStub fallbackEnd() const;
 
   std::shared_ptr<const torch::profiler::impl::Result> result_;
   std::vector<std::string> python_stack_;
diff --git a/torch/csrc/autograd/profiler_legacy.cpp b/torch/csrc/autograd/profiler_legacy.cpp
index 388695957e4..f60c26f2dab 100644
--- a/torch/csrc/autograd/profiler_legacy.cpp
+++ b/torch/csrc/autograd/profiler_legacy.cpp
@@ -140,6 +140,10 @@ struct ProfilerLegacyThreadLocalState : public ProfilerStateBase {
 
   void mark(std::string name, bool include_cuda = true);
 
+  void markKernel(
+      std::string name,
+      torch::profiler::impl::ProfilerEventStub kernel_event);
+
   void setOrAddRemoteProfiledEvents(
       std::vector<LegacyEvent>&& remoteProfiledEvents);
 
@@ -195,7 +199,9 @@ thread_event_lists ProfilerLegacyThreadLocalState::consolidate() {
   return result;
 }
 
-void ProfilerLegacyThreadLocalState::mark(std::string name, bool include_cuda) {
+void ProfilerLegacyThreadLocalState::mark(
+    std::string name,
+    bool include_kernel) {
   if (config_.disabled()) {
     return;
   }
@@ -206,13 +212,29 @@ void ProfilerLegacyThreadLocalState::mark(std::string name, bool include_cuda) {
         EventKind::Mark,
         at::StringView(std::move(name)),
         at::RecordFunction::currentThreadId(),
-        include_cuda &&
-            config_.state == torch::profiler::impl::ProfilerState::CUDA);
+        include_kernel,
+        config_.state);
     evt.setNodeId(at::RecordFunction::getDefaultNodeId());
     getEventList().record(std::move(evt));
   }
 }
 
+void ProfilerLegacyThreadLocalState::markKernel(
+    std::string name,
+    torch::profiler::impl::ProfilerEventStub kernel_event) {
+  if (config_.state == ProfilerState::Disabled) {
+    return;
+  }
+  if (config_.state == ProfilerState::XPU) {
+    getEventList().record(
+        EventKind::Mark,
+        at::StringView(std::move(name)),
+        at::RecordFunction::currentThreadId(),
+        config_.state,
+        kernel_event);
+  }
+}
+
 void ProfilerLegacyThreadLocalState::setOrAddRemoteProfiledEvents(
     std::vector<LegacyEvent>&& remoteProfiledEvents) {
   // Lock to serialize access from multiple callback threads.
@@ -226,7 +248,7 @@ void ProfilerLegacyThreadLocalState::setOrAddRemoteProfiledEvents(
 
 void ProfilerLegacyThreadLocalState::pushRange(
     const at::RecordFunction& fn,
-    const bool record_cuda,
+    const bool include_kernel,
     std::vector<std::vector<int64_t>>&& shapes) {
   if (config_.disabled()) {
     return;
@@ -240,7 +262,8 @@ void ProfilerLegacyThreadLocalState::pushRange(
         EventKind::PushRange,
         at::StringView(std::string(fn.name())),
         at::RecordFunction::currentThreadId(),
-        record_cuda,
+        include_kernel,
+        config_.state,
         fn.handle(),
         std::move(shapes),
         at::RecordFunction::getDefaultNodeId(),
@@ -275,7 +298,7 @@ void ProfilerLegacyThreadLocalState::pushRange(
 
 void ProfilerLegacyThreadLocalState::popRange(
     const at::RecordFunction& fn,
-    const bool record_cuda) {
+    const bool include_kernel) {
   if (config_.disabled()) {
     return;
   }
@@ -290,7 +313,8 @@ void ProfilerLegacyThreadLocalState::popRange(
         EventKind::PopRange,
         at::StringView(""),
         at::RecordFunction::currentThreadId(),
-        record_cuda,
+        include_kernel,
+        config_.state,
         fn.handle());
     evt.setNodeId(at::RecordFunction::getDefaultNodeId());
     getEventList(fn.threadId()).record(std::move(evt));
@@ -309,7 +333,8 @@ void ProfilerLegacyThreadLocalState::reportMemoryUsage(
         EventKind::MemoryAlloc,
         at::StringView(""),
         thread_id,
-        config_.state == torch::profiler::impl::ProfilerState::CUDA);
+        false,
+        config_.state);
     evt.updateMemoryStats(alloc_size, device);
     getEventList(thread_id).record(std::move(evt));
   }
@@ -421,6 +446,10 @@ void enableProfilerLegacy(
       new_config.state != torch::profiler::impl::ProfilerState::NVTX ||
           torch::profiler::impl::cudaStubs()->enabled(),
       "Can't use NVTX profiler - PyTorch was compiled without CUDA");
+  TORCH_CHECK(
+      new_config.state != ProfilerState::ITT ||
+          torch::profiler::impl::xpuStubs()->enabled(),
+      "Can't use Intel(R) VTune Profiler's ITT functionality - PyTorch was compiled without XPU");
 
   TORCH_CHECK(new_config.state != torch::profiler::impl::ProfilerState::KINETO);
 
@@ -434,6 +463,13 @@ void enableProfilerLegacy(
   state->mark("__start_profile", false);
 }
 
+void markKernel(
+    std::string name,
+    torch::profiler::impl::ProfilerEventStub& kernel_event) {
+  auto state_ptr = ProfilerLegacyThreadLocalState::getTLS();
+  state_ptr->markKernel(name, kernel_event);
+}
+
 thread_event_lists disableProfilerLegacy(
     c10::optional<ProfilerDisableOptions> profilerDisableOptions) {
   auto cleanupTLSState =
@@ -472,10 +508,23 @@ void addEventList(std::vector<LegacyEvent>&& profiledEvents) {
   state_ptr->setOrAddRemoteProfiledEvents(std::move(profiledEvents));
 }
 
-void LegacyEvent::record(bool record_cuda) {
-  if (record_cuda) {
-    torch::profiler::impl::cudaStubs()->record(&device_, &cuda_event, &cpu_ns_);
-    return;
+void LegacyEvent::record(bool include_kernel, ProfilerState state) {
+  if (include_kernel) {
+    int device_id;
+    switch (state) {
+      case ProfilerState::CUDA:
+        torch::profiler::impl::cudaStubs()->record(
+            &device_id, &kernel_event_, &cpu_ns_);
+        device_ = at::Device(DeviceType::CUDA, device_id);
+        break;
+      case ProfilerState::XPU:
+        torch::profiler::impl::xpuStubs()->record(
+            &device_id, &kernel_event_, &cpu_ns_);
+        device_ = at::Device(DeviceType::XPU, device_id);
+        break;
+      default:
+        break;
+    }
   }
   cpu_ns_ = torch::profiler::impl::getTime();
 }
@@ -529,7 +578,7 @@ void LegacyEvent::record(bool record_cuda) {
       ivalues.get(EventIValueIdx::CPU_NS).toInt(), // cpu_ns
       ivalues.get(EventIValueIdx::CUDA_RECORDED).toBool(), // was cuda recorded
       ivalues.get(EventIValueIdx::CUDA_MEM_USAGE).toInt(), // cuda memory usage
-      ivalues.get(EventIValueIdx::CUDA_DEVICE).toInt(), // device
+      ivalues.get(EventIValueIdx::CUDA_DEVICE).toDevice(), // device
       ivalues.get(EventIValueIdx::CUDA_US).toInt() // cuda_us
   );
   return evt;
@@ -579,7 +628,24 @@ double LegacyEvent::cudaElapsedUs(const LegacyEvent& e) const {
     return static_cast<double>(e.cuda_us_ - cuda_us_);
   }
   return torch::profiler::impl::cudaStubs()->elapsed(
-      &cuda_event, &e.cuda_event);
+      &kernel_event_, &e.kernel_event_);
+}
+
+double LegacyEvent::xpuElapsedUs() const {
+  if (!hasXpu()) {
+    throw std::logic_error("Events were not recorded for XPU");
+  }
+  return torch::profiler::impl::xpuStubs()->elapsed(&kernel_event_);
+}
+
+double LegacyEvent::xpuElapsedUs(const LegacyEvent& e) const {
+  TORCH_CHECK(e.hasXpu() && hasXpu(), "Events were not recorded for XPU");
+  TORCH_CHECK(
+      e.device() == device(),
+      c10::str(
+          "Events are not on the same device: ", e.device(), " vs ", device()));
+  return torch::profiler::impl::xpuStubs()->elapsed(
+      &kernel_event_, &e.kernel_event_);
 }
 
 static const at::jit::CodeTemplate event_template(R"(
diff --git a/torch/csrc/autograd/profiler_legacy.h b/torch/csrc/autograd/profiler_legacy.h
index a09dab8e98a..f916dcded46 100644
--- a/torch/csrc/autograd/profiler_legacy.h
+++ b/torch/csrc/autograd/profiler_legacy.h
@@ -36,7 +36,8 @@ struct TORCH_API LegacyEvent {
       EventKind kind,
       at::StringView name,
       uint16_t thread_id,
-      bool record_cuda,
+      bool include_kernel,
+      ProfilerState state,
       at::RecordFunctionHandle handle = 0,
       std::vector<std::vector<int64_t>>&& shapes = {},
       int node_id = -1,
@@ -48,7 +49,21 @@ struct TORCH_API LegacyEvent {
         shapes_(shapes),
         node_id_(node_id),
         is_async_(is_async) {
-    record(record_cuda);
+    record(include_kernel, state);
+  }
+
+  // Constructor to be used in marking a kernel event.
+  LegacyEvent(
+      EventKind kind,
+      at::StringView name,
+      uint16_t thread_id,
+      ProfilerState state,
+      torch::profiler::impl::ProfilerEventStub event)
+      : name_(std::move(name)),
+        kind_(kind),
+        thread_id_(thread_id),
+        kernel_event_(event) {
+    record(true, state);
   }
 
   // Constructor to be used in conjunction with LegacyEvent::fromIValue.
@@ -65,7 +80,7 @@ struct TORCH_API LegacyEvent {
       int64_t cpu_ns,
       bool cuda_recorded,
       int64_t cuda_memory_usage = 0,
-      int device = -1,
+      at::Device device = at::Device(DeviceType::CPU),
       double cuda_us = -1)
       : cpu_ns_(cpu_ns),
         name_(std::move(name)),
@@ -82,7 +97,7 @@ struct TORCH_API LegacyEvent {
     // Sanity check values that were deserialized
     TORCH_INTERNAL_ASSERT(cpu_ns_ > 0);
     if (cuda_recorded) {
-      TORCH_INTERNAL_ASSERT(device_ >= 0);
+      TORCH_INTERNAL_ASSERT(device_.index() >= 0);
       TORCH_INTERNAL_ASSERT(cuda_us_ >= 0);
     }
   }
@@ -94,7 +109,7 @@ struct TORCH_API LegacyEvent {
   // Reconstructs an event from IValues given by toIValue.
   static LegacyEvent fromIValue(const at::IValue& eventIValue);
 
-  void record(bool record_cuda);
+  void record(bool include_kernel, ProfilerState state);
 
   std::string kindStr() const {
     switch (kind_) {
@@ -139,13 +154,24 @@ struct TORCH_API LegacyEvent {
     return static_cast<double>(cpu_ns_) / (1000.0);
   }
 
+  bool hasKernel() const {
+    return kernel_event_ != nullptr || (isRemote() && device_.index() != -1);
+  }
+
   double cudaElapsedUs(const LegacyEvent& e) const;
 
   bool hasCuda() const {
-    return cuda_event != nullptr || (isRemote() && device_ != -1);
+    return hasKernel() && device_.type() == DeviceType::CUDA;
+  }
+
+  double xpuElapsedUs() const;
+  double xpuElapsedUs(const LegacyEvent& e) const;
+
+  bool hasXpu() const {
+    return hasKernel() && device_.type() == DeviceType::XPU;
   }
 
-  int device() const {
+  at::Device device() const {
     return device_;
   }
 
@@ -156,6 +182,8 @@ struct TORCH_API LegacyEvent {
         device.is_cpu() || device.type() == c10::DeviceType::MKLDNN ||
         device.type() == c10::DeviceType::IDEEP) {
       cpu_memory_usage_ = alloc_size;
+    } else if (device.is_xpu()) {
+      xpu_memory_usage_ = alloc_size;
     } else {
       LOG(WARNING) << "Unsupported memory profiling device: " << device;
     }
@@ -169,6 +197,10 @@ struct TORCH_API LegacyEvent {
     return cuda_memory_usage_;
   }
 
+  int64_t xpuMemoryUsage() const {
+    return xpu_memory_usage_;
+  }
+
   at::RecordFunctionHandle handle() const {
     return handle_;
   }
@@ -266,8 +298,9 @@ struct TORCH_API LegacyEvent {
   std::vector<std::vector<int64_t>> shapes_;
   int64_t cpu_memory_usage_ = 0;
   int64_t cuda_memory_usage_ = 0;
-  int device_ = -1;
-  torch::profiler::impl::ProfilerVoidEventStub cuda_event = nullptr;
+  int64_t xpu_memory_usage_ = 0;
+  at::Device device_ = at::Device(DeviceType::CPU);
+  torch::profiler::impl::ProfilerEventStub kernel_event_ = nullptr;
   int node_id_ = 0;
   bool is_remote_ = false;
   int64_t cuda_us_ = -1;
@@ -354,6 +387,10 @@ TORCH_API void addEventList(std::vector<LegacyEvent>&& profiledEvents);
 TORCH_API void writeProfilerEventsToStream(
     std::ostream& out,
     const std::vector<LegacyEvent*>& events);
+// Add a kernel event to profile.
+TORCH_API void markKernel(
+    std::string name,
+    torch::profiler::impl::ProfilerEventStub& kernel_event);
 
 // Usage:
 //   {
diff --git a/torch/csrc/profiler/collection.h b/torch/csrc/profiler/collection.h
index 20ef0c85836..e0c675e008a 100644
--- a/torch/csrc/profiler/collection.h
+++ b/torch/csrc/profiler/collection.h
@@ -116,8 +116,8 @@ using jit_modules_t = std::vector<std::string>;
 using extra_args_t = std::unordered_map<std::string, c10::IValue>;
 
 struct FallbackPair {
-  ProfilerVoidEventStub device_event_start_ = nullptr;
-  ProfilerVoidEventStub device_event_end_ = nullptr;
+  ProfilerEventStub device_event_start_ = nullptr;
+  ProfilerEventStub device_event_end_ = nullptr;
 };
 
 template <>
diff --git a/torch/csrc/profiler/orchestration/observer.h b/torch/csrc/profiler/orchestration/observer.h
index 5d42f9234c3..fe0e1ad219d 100644
--- a/torch/csrc/profiler/orchestration/observer.h
+++ b/torch/csrc/profiler/orchestration/observer.h
@@ -24,6 +24,7 @@ enum class C10_API_ENUM ProfilerState {
   Disabled = 0,
   CPU, // CPU-only profiling
   CUDA, // CPU + CUDA events
+  XPU, // CPU + XPU events
   NVTX, // only emit NVTX markers
   ITT, // only emit ITT markers
   KINETO, // use libkineto
diff --git a/torch/csrc/profiler/python/init.cpp b/torch/csrc/profiler/python/init.cpp
index 14eb91c64f8..70c7c82b6ea 100644
--- a/torch/csrc/profiler/python/init.cpp
+++ b/torch/csrc/profiler/python/init.cpp
@@ -235,6 +235,7 @@ void initPythonBindings(PyObject* module) {
       .value("Disabled", ProfilerState::Disabled)
       .value("CPU", ProfilerState::CPU)
       .value("CUDA", ProfilerState::CUDA)
+      .value("XPU", ProfilerState::XPU)
       .value("NVTX", ProfilerState::NVTX)
       .value("ITT", ProfilerState::ITT)
       .value("KINETO", ProfilerState::KINETO)
diff --git a/torch/csrc/profiler/stubs/base.cpp b/torch/csrc/profiler/stubs/base.cpp
index a7b928b44a0..2eacd70524d 100644
--- a/torch/csrc/profiler/stubs/base.cpp
+++ b/torch/csrc/profiler/stubs/base.cpp
@@ -12,14 +12,18 @@ namespace {
 struct DefaultStubs : public ProfilerStubs {
   DefaultStubs(const char* name) : name_{name} {}
 
-  void record(int*, ProfilerVoidEventStub*, int64_t*) const override {
+  void record(int*, ProfilerEventStub*, int64_t*) const override {
     fail();
   }
-  float elapsed(const ProfilerVoidEventStub*, const ProfilerVoidEventStub*)
+  float elapsed(const ProfilerEventStub*, const ProfilerEventStub*)
       const override {
     fail();
     return 0.f;
   }
+  virtual float elapsed(const ProfilerEventStub* event) const override {
+    fail();
+    return 0.f;
+  }
   void mark(const char*) const override {
     fail();
   }
@@ -75,6 +79,7 @@ struct DefaultStubs : public ProfilerStubs {
 REGISTER_DEFAULT(cuda, CUDA)
 REGISTER_DEFAULT(itt, ITT)
 REGISTER_DEFAULT(privateuse1, PrivateUse1)
+REGISTER_DEFAULT(xpu, XPU)
 #undef REGISTER_DEFAULT
 
 } // namespace impl
diff --git a/torch/csrc/profiler/stubs/base.h b/torch/csrc/profiler/stubs/base.h
index bac3f5ed378..97ab1bd984d 100644
--- a/torch/csrc/profiler/stubs/base.h
+++ b/torch/csrc/profiler/stubs/base.h
@@ -6,26 +6,29 @@
 #include <c10/util/strong_type.h>
 #include <torch/csrc/Export.h>
 
-struct CUevent_st;
-
 namespace torch {
 namespace profiler {
 namespace impl {
 
+class KernelEventBase {
+ public:
+  virtual ~KernelEventBase() = default;
+};
+
 // ----------------------------------------------------------------------------
 // -- Annotation --------------------------------------------------------------
 // ----------------------------------------------------------------------------
-using ProfilerEventStub = std::shared_ptr<CUevent_st>;
-using ProfilerVoidEventStub = std::shared_ptr<void>;
+using ProfilerEventStub = std::shared_ptr<KernelEventBase>;
 
 struct TORCH_API ProfilerStubs {
   virtual void record(
       int* device,
-      ProfilerVoidEventStub* event,
+      ProfilerEventStub* event,
       int64_t* cpu_ns) const = 0;
   virtual float elapsed(
-      const ProfilerVoidEventStub* event,
-      const ProfilerVoidEventStub* event2) const = 0;
+      const ProfilerEventStub* event,
+      const ProfilerEventStub* event2) const = 0;
+  virtual float elapsed(const ProfilerEventStub* event) const = 0;
   virtual void mark(const char* name) const = 0;
   virtual void rangePush(const char* name) const = 0;
   virtual void rangePop() const = 0;
@@ -43,6 +46,8 @@ TORCH_API void registerITTMethods(ProfilerStubs* stubs);
 TORCH_API const ProfilerStubs* ittStubs();
 TORCH_API void registerPrivateUse1Methods(ProfilerStubs* stubs);
 TORCH_API const ProfilerStubs* privateuse1Stubs();
+TORCH_API void registerXPUMethods(ProfilerStubs* stubs);
+TORCH_API const ProfilerStubs* xpuStubs();
 
 using vulkan_id_t = strong::type<
     int64_t,
diff --git a/torch/csrc/profiler/stubs/cuda.cpp b/torch/csrc/profiler/stubs/cuda.cpp
index dec87576f36..946b5e6b7c2 100644
--- a/torch/csrc/profiler/stubs/cuda.cpp
+++ b/torch/csrc/profiler/stubs/cuda.cpp
@@ -7,6 +7,8 @@
 #include <torch/csrc/profiler/stubs/base.h>
 #include <torch/csrc/profiler/util.h>
 
+struct CUevent_st;
+
 namespace torch {
 namespace profiler {
 namespace impl {
@@ -35,8 +37,24 @@ static inline void cudaCheck(cudaError_t result, const char* file, int line) {
 }
 #define TORCH_CUDA_CHECK(result) cudaCheck(result, __FILE__, __LINE__);
 
+class CUDAEventProfiler : public KernelEventBase {
+ public:
+  CUDAEventProfiler(CUevent_st* evt_ptr = nullptr)
+      : event_(evt_ptr, CUDAEventDestory){};
+  virtual ~CUDAEventProfiler() = default;
+  CUevent_st* get() const {
+    return event_.get();
+  }
+
+ private:
+  static void CUDAEventDestory(CUevent_st* ptr) {
+    TORCH_CUDA_CHECK(cudaEventDestroy(ptr));
+  }
+  std::unique_ptr<CUevent_st, std::function<void(CUevent_st*)>> event_;
+};
+
 struct CUDAMethods : public ProfilerStubs {
-  void record(int* device, ProfilerVoidEventStub* event, int64_t* cpu_ns)
+  void record(int* device, ProfilerEventStub* event, int64_t* cpu_ns)
       const override {
     if (device) {
       TORCH_CUDA_CHECK(c10::cuda::GetDevice(device));
@@ -44,9 +62,8 @@ struct CUDAMethods : public ProfilerStubs {
     // NOLINTNEXTLINE(cppcoreguidelines-init-variables)
     CUevent_st* cuda_event_ptr;
     TORCH_CUDA_CHECK(cudaEventCreate(&cuda_event_ptr));
-    *event = std::shared_ptr<CUevent_st>(cuda_event_ptr, [](CUevent_st* ptr) {
-      TORCH_CUDA_CHECK(cudaEventDestroy(ptr));
-    });
+    auto cuda_event_stub = std::make_shared<CUDAEventProfiler>(cuda_event_ptr);
+    *event = cuda_event_stub;
     auto stream = at::cuda::getCurrentCUDAStream();
     if (cpu_ns) {
       *cpu_ns = torch::profiler::impl::getTime();
@@ -54,20 +71,26 @@ struct CUDAMethods : public ProfilerStubs {
     TORCH_CUDA_CHECK(cudaEventRecord(cuda_event_ptr, stream));
   }
 
-  float elapsed(
-      const ProfilerVoidEventStub* event_,
-      const ProfilerVoidEventStub* event2_) const override {
-    auto event = (const ProfilerEventStub*)(event_);
-    auto event2 = (const ProfilerEventStub*)(event2_);
-    TORCH_CUDA_CHECK(cudaEventSynchronize(event->get()));
-    TORCH_CUDA_CHECK(cudaEventSynchronize(event2->get()));
+  float elapsed(const ProfilerEventStub* event, const ProfilerEventStub* event2)
+      const override {
+    CUDAEventProfiler* cuda_event_ =
+        dynamic_cast<CUDAEventProfiler*>(event->get());
+    CUDAEventProfiler* cuda_event2_ =
+        dynamic_cast<CUDAEventProfiler*>(event2->get());
+    TORCH_CUDA_CHECK(cudaEventSynchronize(cuda_event_->get()));
+    TORCH_CUDA_CHECK(cudaEventSynchronize(cuda_event2_->get()));
     // NOLINTNEXTLINE(cppcoreguidelines-init-variables)
     float ms;
-    TORCH_CUDA_CHECK(cudaEventElapsedTime(&ms, event->get(), event2->get()));
+    TORCH_CUDA_CHECK(
+        cudaEventElapsedTime(&ms, cuda_event_->get(), cuda_event2_->get()));
     // NOLINTNEXTLINE(bugprone-narrowing-conversions,cppcoreguidelines-avoid-magic-numbers,cppcoreguidelines-narrowing-conversions)
     return ms * 1000.0;
   }
 
+  float elapsed(const ProfilerEventStub* event) const override {
+    TORCH_CHECK(false, "Profiler cannot use this method on CUDA backend.");
+  }
+
   void mark(const char* name) const override {
     // NOLINTNEXTLINE(cppcoreguidelines-init-variables)
     ::nvtxMark(name);
diff --git a/torch/csrc/profiler/stubs/itt.cpp b/torch/csrc/profiler/stubs/itt.cpp
index 61ae4cb7c49..7d459fcd9f4 100644
--- a/torch/csrc/profiler/stubs/itt.cpp
+++ b/torch/csrc/profiler/stubs/itt.cpp
@@ -10,12 +10,16 @@ namespace impl {
 namespace {
 
 struct ITTMethods : public ProfilerStubs {
-  void record(int* device, ProfilerVoidEventStub* event, int64_t* cpu_ns)
+  void record(int* device, ProfilerEventStub* event, int64_t* cpu_ns)
       const override {}
 
   float elapsed(
-      const ProfilerVoidEventStub* event,
-      const ProfilerVoidEventStub* event2) const override {
+      const ProfilerEventStub* event,
+      const ProfilerEventStub* event2) const override {
+    return 0;
+  }
+
+  virtual float elapsed(const ProfilerEventStub* event) const override {
     return 0;
   }
 
diff --git a/torch/testing/_internal/distributed/rpc/rpc_test.py b/torch/testing/_internal/distributed/rpc/rpc_test.py
index bc3bbe2ebcf..624da46c612 100644
--- a/torch/testing/_internal/distributed/rpc/rpc_test.py
+++ b/torch/testing/_internal/distributed/rpc/rpc_test.py
@@ -4616,9 +4616,9 @@ class CudaRpcTest(RpcAgentTestFixture):
                     self.assertEqual(1, len(event.kernels))
                     kernel = event.kernels[0]
                     if event.node_id == dst_cuda_0:
-                        self.assertEqual(kernel.device, 0)
+                        self.assertEqual(kernel.device, torch.device("cuda:{}".format(0)))
                     if event.node_id == dst_cuda_1:
-                        self.assertEqual(kernel.device, 1)
+                        self.assertEqual(kernel.device, torch.device("cuda:{}".format(1)))
                     self.assertGreater(event.cuda_time, 0)
 
         # Validate that EXPECTED_REMOTE_EVENTS is a subset of remotely profiled
-- 
2.34.1

